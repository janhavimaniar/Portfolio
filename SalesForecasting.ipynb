{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPuGe4ucohJa"
      },
      "outputs": [],
      "source": [
        "## Install libraries\n",
        "%pip install -Uq upgini catboost\n",
        "\n",
        "from os.path import exists\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Get data\n",
        "df_path = \"train.csv.zip\" if exists (\"train.csv.zip\") else \"https://github.com/upgini/upgini/raw/main/notebooks/train.csv.zip\"\n",
        "df = pd.read_csv(df_path)\n",
        "\n",
        "\n",
        "## Data Cleaning and Transformations\n",
        "df[\"store\"] = df[\"store\"].astype(str)\n",
        "df[\"item\"] = df[\"item\"].astype(str)\n",
        "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "\n",
        "df.sort_values(\"date\", inplace=True)\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Lp1XhWTco_vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Split data into training and testing sets\n",
        "\n",
        "df = df.sample(n=1000, random_state=0)\n",
        "\n",
        "# Training dataset - all data from 2013-2016\n",
        "train = df[df['date'] < \"2017-01-01\"]\n",
        "\n",
        "# Testing dataset - all data from 2017\n",
        "test = df[df['date'] >= \"2017-01-01\"]\n",
        "\n",
        "# Take random sample of data\n",
        "df = df.sample(n=1000, random_state = 0)\n",
        "\n",
        "#verify both have enough values\n",
        "print(f\"Train rows: {len(train)}, Test rows: {len(test)}\")\n",
        "\n",
        "#split datasets into features and target\n",
        "train_features = train.drop(columns = [\"sales\"])\n",
        "train_target = train[\"sales\"]\n",
        "\n",
        "test_features = test.drop(columns = [\"sales\"])\n",
        "test_target = test[\"sales\"]\n"
      ],
      "metadata": {
        "id": "oDvkcgzRdQhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Enrich features to account for other relevant variables\n",
        "\n",
        "from upgini import FeaturesEnricher, SearchKey\n",
        "from upgini.metadata import CVType\n",
        "\n",
        "enricher = FeaturesEnricher(\n",
        "    search_keys= {\n",
        "        \"date\": SearchKey.DATE,\n",
        "    },\n",
        "    cv= CVType.time_series\n",
        ")\n",
        "\n",
        "enricher.fit(train_features,\n",
        "             train_target,\n",
        "             eval_set=[(test_features, test_target)])"
      ],
      "metadata": {
        "id": "HRWVuyZ2Bw0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define model\n",
        "from catboost import CatBoostRegressor\n",
        "from catboost.utils import eval_metric\n",
        "\n",
        "model = CatBoostRegressor(verbose=False, allow_writing_files=False, random_state=0)\n",
        "\n",
        "enricher.calculate_metrics(\n",
        "    train_features, train_target,\n",
        "    eval_set=[(test_features, test_target)],\n",
        "    estimator = model,\n",
        "    scoring = \"mean_absolute_percentage_error\"\n",
        ")"
      ],
      "metadata": {
        "id": "PcpvXF9mG2jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train model\n",
        "enriched_train_features = enricher.transform(train_features, y = train_target, keep_input=True)\n",
        "enriched_test_features = enricher.transform(test_features, y = test_target, keep_input=True)\n",
        "enriched_train_features.head()"
      ],
      "metadata": {
        "id": "2O6hhmymeqEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model without enrichment\n",
        "model.fit(train_features, train_target)\n",
        "preds = model.predict(test_features)\n",
        "eval_metric(test_target.values, preds, \"SMAPE\") #gives error rate of model"
      ],
      "metadata": {
        "id": "BSEZd5KMf2uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model with enrichment\n",
        "model.fit(enriched_train_features, train_target)\n",
        "enriched_preds = model.predict(enriched_test_features)\n",
        "eval_metric(test_target.values, enriched_preds, \"SMAPE\") #gives error rate of model"
      ],
      "metadata": {
        "id": "o6J2e6H7gdtn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}